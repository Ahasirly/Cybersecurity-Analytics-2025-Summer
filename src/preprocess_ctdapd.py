# CTDAPD (Cyber Threat Detection and Attack Pattern Dataset) æ•°æ®é›†é¢„å¤„ç†è„šæœ¬
# 
# æ•°æ®é›†è¯´æ˜ï¼š
# - æ¥æºï¼šç½‘ç»œæµé‡æ•°æ®
# - ç›®æ ‡ï¼šæ£€æµ‹ç½‘ç»œæ”»å‡»
# - ç‰¹å¾ï¼šåŒ…å«ç½‘ç»œæµé‡ç‰¹å¾ï¼ˆå¦‚åŒ…å¤§å°ã€åè®®ç±»å‹ã€æµæŒç»­æ—¶é—´ç­‰ï¼‰
# - æ ‡ç­¾ï¼šäºŒåˆ†ç±»ï¼ˆæ­£å¸¸æµé‡ vs æ”»å‡»æµé‡ï¼‰
#
# é¢„å¤„ç†æ­¥éª¤æ¦‚è¿°ï¼š
# 1. æ•°æ®æ¸…ç†ï¼šç§»é™¤æ— å…³ç‰¹å¾ï¼Œå¤„ç†ç¼ºå¤±å€¼
# 2. ç‰¹å¾å·¥ç¨‹ï¼šç¼–ç åˆ†ç±»å˜é‡ï¼Œæ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾
# 3. å¼‚å¸¸å€¼å¤„ç†ï¼šä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å’Œç§»é™¤å¼‚å¸¸å€¼
# 4. æ•°æ®åˆ†å‰²ï¼šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
# 5. ä¿å­˜å¤„ç†åçš„æ•°æ®ï¼šåˆ†åˆ«ä¿å­˜æ¸…ç†åçš„å®Œæ•´æ•°æ®é›†ã€è®­ç»ƒé›†å’Œæµ‹è¯•é›†

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import os

def preprocess_ctdapd_dataset():
    # CTDAPDæ•°æ®é›†é¢„å¤„ç†ä¸»å‡½æ•°
    #
    # åŠŸèƒ½ï¼š
    # - åŠ è½½åŸå§‹CTDAPDæ•°æ®é›†
    # - æ‰§è¡Œå®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹
    # - ä¿å­˜å¤„ç†åçš„æ•°æ®é›†
    # - ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
    #
    # è¿”å›å€¼ï¼š
    # - X_train: è®­ç»ƒé›†ç‰¹å¾
    # - X_test: æµ‹è¯•é›†ç‰¹å¾
    # - y_train: è®­ç»ƒé›†æ ‡ç­¾
    # - y_test: æµ‹è¯•é›†æ ‡ç­¾
    # - feature_names: ç‰¹å¾ååˆ—è¡¨
    
    print("å¼€å§‹é¢„å¤„ç†CTDAPDæ•°æ®é›†...")
    
    # 1. åŠ è½½åŸå§‹æ•°æ®
    # ä»CSVæ–‡ä»¶åŠ è½½åŸå§‹CTDAPDæ•°æ®é›†
    df = pd.read_csv('Datasets/original/CTDAPD_Dataset.csv')
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"åŸå§‹åˆ—å: {list(df.columns)}")
    
    # æ£€æŸ¥ç›®æ ‡å˜é‡åˆ†å¸ƒï¼Œäº†è§£æ•°æ®é›†æ˜¯å¦å¹³è¡¡
    print(f"ç›®æ ‡å˜é‡åˆ†å¸ƒ: {df['Label'].value_counts()}")
    
    # 2. ç‰¹å¾é€‰æ‹©
    # ç§»é™¤å¯¹æ¨¡å‹è®­ç»ƒæ— ç”¨çš„åˆ—ï¼š
    # - Dateï¼šæ—¶é—´æˆ³å¯¹æ£€æµ‹æ”»å‡»æ¨¡å¼æ— ç›´æ¥å¸®åŠ©
    # - Source_IP/Destination_IPï¼šå…·ä½“IPåœ°å€å¯èƒ½å¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆ overfitting 
    print("\n1. ç§»é™¤ä¸éœ€è¦çš„åˆ—...")
    cols_to_drop = ['Date', 'Source_IP', 'Destination_IP']
    df_clean = df.drop([col for col in cols_to_drop if col in df.columns], axis=1)
    print(f"ç§»é™¤åˆ—åå½¢çŠ¶: {df_clean.shape}")
    
    # 3. ç¼ºå¤±å€¼å¤„ç†
    # ç»Ÿè®¡æ¯ä¸ªç‰¹å¾çš„ç¼ºå¤±å€¼æ•°é‡ï¼Œä¸ºåç»­å¤„ç†æä¾›ä¾æ®
    print("\n2. å¤„ç†ç¼ºå¤±å€¼...")
    print("ç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_counts = df_clean.isnull().sum()
    print(missing_counts[missing_counts > 0])
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡ï¼Œæ–¹ä¾¿åˆ†åˆ«å¤„ç†
    X = df_clean.drop(['Label'], axis=1)
    y = df_clean['Label']
    
    # 4. åˆ†ç±»ç‰¹å¾å¤„ç†
    # å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼ä»¥ä¾›æ¨¡å‹ä½¿ç”¨
    print("\n3. å¤„ç†åˆ†ç±»ç‰¹å¾...")
    categorical_cols = X.select_dtypes(include=['object']).columns
    print(f"åˆ†ç±»ç‰¹å¾: {list(categorical_cols)}")
    
    X_processed = X.copy()
    label_encoders = {}
    
    for col in categorical_cols:
        print(f"å¤„ç† {col}...")
        # ä½¿ç”¨'Unknown'å¡«å……ç¼ºå¤±å€¼ï¼Œä¿æŒæ•°æ®å®Œæ•´æ€§
        X_processed[col] = X_processed[col].fillna('Unknown')
        
        # ä½¿ç”¨LabelEncoderå°†åˆ†ç±»å€¼è½¬æ¢ä¸ºæ•°å€¼
        le = LabelEncoder()
        X_processed[col] = le.fit_transform(X_processed[col])
        label_encoders[col] = le
        
        print(f"  - {col}: {len(le.classes_)} ä¸ªç±»åˆ«")
        print(f"  - ç±»åˆ«: {le.classes_}")
    
    # 5. æ•°å€¼ç‰¹å¾å¤„ç†
    # å¤„ç†æ•°å€¼ç‰¹å¾ä¸­çš„å¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼
    print("\n4. å¤„ç†æ•°å€¼ç‰¹å¾...")
    numeric_cols = X_processed.select_dtypes(include=[np.number]).columns
    print(f"æ•°å€¼ç‰¹å¾æ•°é‡: {len(numeric_cols)}")
    
    # å¤„ç†æ— ç©·å€¼ï¼šå°†æ— ç©·å€¼æ›¿æ¢ä¸ºNaNï¼Œåç»­ç”¨ä¸­ä½æ•° median å¡«å……
    print("å¤„ç†æ— ç©·å€¼...")
    inf_counts = np.isinf(X_processed[numeric_cols]).sum()
    if inf_counts.sum() > 0:
        print("å‘ç°æ— ç©·å€¼:")
        print(inf_counts[inf_counts > 0])
        X_processed[numeric_cols] = X_processed[numeric_cols].replace([np.inf, -np.inf], np.nan)
    
    # ä½¿ç”¨ä¸­ä½æ•°å¡«å……æ•°å€¼ç‰¹å¾çš„ç¼ºå¤±å€¼
    # é€‰æ‹©ä¸­ä½æ•°è€Œä¸æ˜¯å¹³å‡æ•°ï¼Œå› ä¸ºä¸­ä½æ•°å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
    print("å¤„ç†æ•°å€¼ç‰¹å¾ç¼ºå¤±å€¼...")
    X_processed[numeric_cols] = X_processed[numeric_cols].fillna(X_processed[numeric_cols].median())
    
    # 6. å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†
    # ä½¿ç”¨IQRï¼ˆå››åˆ†ä½è·ï¼‰æ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
    # IQR = Q3 - Q1ï¼Œå¼‚å¸¸å€¼å®šä¹‰ä¸ºå°äº(Q1 - 1.5*IQR)æˆ–å¤§äº(Q3 + 1.5*IQR)çš„å€¼
    print("\n5. å¤„ç†å¼‚å¸¸å€¼...")
    Q1 = X_processed[numeric_cols].quantile(0.25)
    Q3 = X_processed[numeric_cols].quantile(0.75)
    IQR = Q3 - Q1
    
    # å®šä¹‰å¼‚å¸¸å€¼è¾¹ç•Œ
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    # æ ‡è®°å¹¶ç§»é™¤å¼‚å¸¸å€¼
    outlier_mask = ((X_processed[numeric_cols] < lower_bound) | (X_processed[numeric_cols] > upper_bound)).any(axis=1)
    print(f"æ£€æµ‹åˆ° {outlier_mask.sum()} ä¸ªå¼‚å¸¸æ ·æœ¬ ({outlier_mask.sum()/len(X_processed)*100:.2f}%)")
    
    X_clean = X_processed[~outlier_mask]
    y_clean = y[~outlier_mask]
    print(f"æ¸…ç†åæ•°æ®å½¢çŠ¶: {X_clean.shape}")
    
    # 7. ç›®æ ‡å˜é‡ç¼–ç 
    # å°†ç›®æ ‡å˜é‡ï¼ˆLabelï¼‰ç¼–ç ä¸ºæ•°å€¼ï¼š0è¡¨ç¤ºæ­£å¸¸æµé‡ï¼Œ1è¡¨ç¤ºæ”»å‡»
    print("\n6. ç¼–ç ç›®æ ‡å˜é‡...")
    label_encoder_y = LabelEncoder()
    y_encoded = label_encoder_y.fit_transform(y_clean)
    print(f"ç›®æ ‡å˜é‡ç¼–ç : {dict(zip(label_encoder_y.classes_, label_encoder_y.transform(label_encoder_y.classes_)))}")
    print(f"ç¼–ç ååˆ†å¸ƒ: {pd.Series(y_encoded).value_counts().sort_index()}")
    
    # 8. æ•°æ®é›†åˆ†å‰²
    # ä½¿ç”¨åˆ†å±‚æŠ½æ ·ï¼ˆstratifyï¼‰ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ç±»åˆ«åˆ†å¸ƒä¸€è‡´
    print("\n7. åˆ†å‰²æ•°æ®...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_clean, y_encoded, 
        test_size=0.2,          # 80%è®­ç»ƒï¼Œ20%æµ‹è¯•
        random_state=42,        # å›ºå®šéšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
        stratify=y_encoded      # ä¿æŒåˆ†å‰²åçš„ç±»åˆ«åˆ†å¸ƒ
    )
    
    print(f"è®­ç»ƒé›†: {X_train.shape}")
    print(f"æµ‹è¯•é›†: {X_test.shape}")
    print(f"è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ: {pd.Series(y_train).value_counts().sort_index()}")
    print(f"æµ‹è¯•é›†ç±»åˆ«åˆ†å¸ƒ: {pd.Series(y_test).value_counts().sort_index()}")
    
    # 9. ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®
    # å°†å¤„ç†åçš„æ•°æ®ä¿å­˜ä¸ºCSVæ ¼å¼ï¼Œä¾¿äºåç»­ä½¿ç”¨
    print("\n8. ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®...")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs('Datasets/cleaned/train', exist_ok=True)
    os.makedirs('Datasets/cleaned/test', exist_ok=True)
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    train_df = pd.DataFrame(X_train, columns=X_clean.columns)
    train_df['Label'] = y_train
    train_df.to_csv('Datasets/cleaned/train/CTDAPD_train.csv', index=False)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    test_df = pd.DataFrame(X_test, columns=X_clean.columns)
    test_df['Label'] = y_test
    test_df.to_csv('Datasets/cleaned/test/CTDAPD_test.csv', index=False)
    
    # ä¿å­˜å®Œæ•´çš„æ¸…ç†åæ•°æ®é›†
    full_clean_df = pd.DataFrame(X_clean, columns=X_clean.columns)
    full_clean_df['Label'] = y_encoded
    full_clean_df.to_csv('Datasets/cleaned/CTDAPD_cleaned.csv', index=False)
    
    print("é¢„å¤„ç†å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜:")
    print("- Datasets/cleaned/train/CTDAPD_train.csv")
    print("- Datasets/cleaned/test/CTDAPD_test.csv") 
    print("- Datasets/cleaned/CTDAPD_cleaned.csv")
    
    # 10. ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
    # æ€»ç»“é¢„å¤„ç†ç»“æœï¼Œå±•ç¤ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®è´¨é‡æŠ¥å‘Š")
    print("="*60)
    print(f"åŸå§‹æ•°æ®: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")
    print(f"æ¸…ç†åæ•°æ®: {X_clean.shape[0]} è¡Œ, {X_clean.shape[1]} åˆ—")
    print(f"æ•°æ®ä¿ç•™ç‡: {X_clean.shape[0]/df.shape[0]*100:.2f}%")
    print(f"ç‰¹å¾æ•°é‡: {X_clean.shape[1]}")
    print(f"æ•°å€¼ç‰¹å¾: {len(X_clean.select_dtypes(include=[np.number]).columns)}")
    print(f"åˆ†ç±»ç‰¹å¾: {len(categorical_cols)}")
    print(f"ç›®æ ‡å˜é‡ç±»åˆ«: {len(label_encoder_y.classes_)}")
    print(f"ç±»åˆ«å¹³è¡¡: Normal={pd.Series(y_encoded).value_counts()[0]}, Attack={pd.Series(y_encoded).value_counts()[1]}")
    
    return X_train, X_test, y_train, y_test, X_clean.columns

if __name__ == "__main__":
    try:
        X_train, X_test, y_train, y_test, feature_names = preprocess_ctdapd_dataset()
        print("\nâœ… CTDAPDæ•°æ®é›†é¢„å¤„ç†æˆåŠŸå®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ é¢„å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc() 