{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# CTDAPD网络攻击检测模型比较实验 (Colab版本)\n",
        "\n",
        "本notebook包含了在CTDAPD数据集上进行的网络攻击检测模型比较实验。\n",
        "\n",
        "## 环境设置\n",
        "1. 检查GPU可用性\n",
        "2. 安装必要的包\n",
        "3. 导入数据\n",
        "4. 训练和评估模型\n",
        "\n",
        "## 使用说明\n",
        "1. 点击\"运行时\" -> \"更改运行时类型\" -> 选择\"GPU\"\n",
        "2. 按顺序运行所有单元格\n",
        "3. 观察不同模型的性能比较\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 检查GPU是否可用\n",
        "import torch\n",
        "print(\"PyTorch版本:\", torch.__version__)\n",
        "print(\"CUDA是否可用:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU型号:\", torch.cuda.get_device_name(0))\n",
        "    print(\"GPU数量:\", torch.cuda.device_count())\n",
        "\n",
        "# 安装必要的包\n",
        "!pip install -q pandas numpy scikit-learn xgboost lightgbm imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import time\n",
        "\n",
        "# 设置随机种子\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义CNN模型\n",
        "class CNNModel(torch.nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(CNNModel, self).__init__()\n",
        "        # 第一个卷积层\n",
        "        self.conv1 = torch.nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(32)\n",
        "        \n",
        "        # 第二个卷积层\n",
        "        self.conv2 = torch.nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
        "        \n",
        "        # 计算全连接层的输入维度\n",
        "        # 经过两次池化，特征维度会减半两次\n",
        "        self.feature_size = input_size\n",
        "        self.fc_input_size = 64 * (self.feature_size // 4)\n",
        "        \n",
        "        # 全连接层\n",
        "        self.fc1 = torch.nn.Linear(self.fc_input_size, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 1)\n",
        "        \n",
        "        # Dropout层\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        \n",
        "        # 池化层\n",
        "        self.pool = torch.nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # 添加通道维度 [batch_size, 1, features]\n",
        "        x = x.unsqueeze(1)\n",
        "        \n",
        "        # 第一个卷积块\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # 第二个卷积块\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        # 展平\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # 全连接层\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        \n",
        "        return x\n",
        "\n",
        "# 准备数据函数\n",
        "def prepare_data_for_cnn(X):\n",
        "    return torch.FloatTensor(X.values if isinstance(X, pd.DataFrame) else X)\n",
        "\n",
        "# 准备数据函数\n",
        "def prepare_data_for_cnn(X):\n",
        "    return torch.FloatTensor(X.values if isinstance(X, pd.DataFrame) else X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 从Google Drive挂载数据集\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 设置数据集路径（假设你已经在Google Drive中创建了相应的文件夹）\n",
        "DRIVE_PATH = '/content/drive/MyDrive/Cybersecurity-Analytics'\n",
        "DATASET_PATH = f'{DRIVE_PATH}/CTDAPD_cleaned.csv'\n",
        "\n",
        "# 检查数据集是否存在\n",
        "import os\n",
        "if not os.path.exists(DRIVE_PATH):\n",
        "    print(f\"创建目录: {DRIVE_PATH}\")\n",
        "    os.makedirs(DRIVE_PATH)\n",
        "    \n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    print(f\"警告: 数据集文件不存在于 {DATASET_PATH}\")\n",
        "    print(\"请确保已将CTDAPD_cleaned.csv复制到Google Drive的Cybersecurity-Analytics文件夹中\")\n",
        "    raise FileNotFoundError(f\"找不到数据集文件: {DATASET_PATH}\")\n",
        "\n",
        "# 读取数据集\n",
        "print(f\"从Google Drive读取数据集: {DATASET_PATH}\")\n",
        "data = pd.read_csv(DATASET_PATH)\n",
        "\n",
        "# 显示数据集信息\n",
        "print(\"\\n数据集基本信息:\")\n",
        "print(data.info())\n",
        "\n",
        "print(\"\\n特征列表:\")\n",
        "feature_columns = [col for col in data.columns if col != 'Label']\n",
        "print(feature_columns)\n",
        "\n",
        "print(\"\\n数据集形状:\", data.shape)\n",
        "print(\"\\n类别分布:\\n\", data['Label'].value_counts())\n",
        "\n",
        "# 显示一些基本统计信息\n",
        "print(\"\\n数值特征的基本统计信息:\")\n",
        "print(data.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 数据预处理\n",
        "print(\"开始数据预处理...\")\n",
        "\n",
        "# 分离特征和标签\n",
        "X = data.drop('Label', axis=1)\n",
        "y = data['Label']\n",
        "\n",
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 特征缩放\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 应用SMOTE平衡数据集\n",
        "print(\"\\n应用SMOTE平衡数据集...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"训练集形状:\", X_train_balanced.shape)\n",
        "print(\"测试集形状:\", X_test_scaled.shape)\n",
        "print(\"\\n平衡后的类别分布:\\n\", pd.Series(y_train_balanced).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义评估函数\n",
        "def evaluate_model(y_true, y_pred, model_name, classifier_type, train_time, predict_time):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    auc_roc = roc_auc_score(y_true, y_pred)\n",
        "    \n",
        "    print(f\"\\n{model_name} 结果:\")\n",
        "    print(f\"分类器类型: {classifier_type}\")\n",
        "    print(f\"准确率: {accuracy:.4f}\")\n",
        "    print(f\"精确率: {precision:.4f}\")\n",
        "    print(f\"召回率: {recall:.4f}\")\n",
        "    print(f\"F1分数: {f1:.4f}\")\n",
        "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
        "    print(f\"训练时间: {train_time:.2f}s\")\n",
        "    print(f\"预测时间: {predict_time:.2f}s\")\n",
        "    \n",
        "    print(\"\\n分类报告:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    print(\"混淆矩阵:\")\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    print(pd.DataFrame(conf_matrix, \n",
        "                      columns=['预测:攻击', '预测:正常'],\n",
        "                      index=['实际:攻击', '实际:正常']))\n",
        "    \n",
        "    return {\n",
        "        'model_name': model_name,\n",
        "        'classifier_type': classifier_type,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'auc_roc': auc_roc,\n",
        "        'train_time': train_time,\n",
        "        'predict_time': predict_time,\n",
        "        'confusion_matrix': conf_matrix\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 训练和评估传统机器学习模型\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(random_state=42),\n",
        "    'LightGBM': LGBMClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'Neural Network': MLPClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n训练 {name}...\")\n",
        "    \n",
        "    # 训练\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_balanced, y_train_balanced)\n",
        "    train_time = time.time() - start_time\n",
        "    \n",
        "    # 预测\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    predict_time = time.time() - start_time\n",
        "    \n",
        "    # 评估\n",
        "    result = evaluate_model(y_test, y_pred, name, type(model).__name__, \n",
        "                          train_time, predict_time)\n",
        "    results.append(result)\n",
        "\n",
        "# 找出最佳模型\n",
        "best_model = max(results, key=lambda x: x['f1'])\n",
        "print(\"\\n最佳模型性能总结\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"模型: {best_model['model_name']}\")\n",
        "print(f\"分类器类型: {best_model['classifier_type']}\")\n",
        "print(f\"准确率: {best_model['accuracy']:.4f}\")\n",
        "print(f\"F1分数: {best_model['f1']:.4f}\")\n",
        "print(f\"训练时间: {best_model['train_time']:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 训练和评估CNN模型\n",
        "print(\"\\n评估CNN模型...\")\n",
        "print(f\"训练数据形状: {X_train_balanced.shape}\")\n",
        "print(f\"测试数据形状: {X_test_scaled.shape}\")\n",
        "\n",
        "# 检查是否有可用的GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "# 准备数据\n",
        "print(\"准备数据...\")\n",
        "X_train_cnn = prepare_data_for_cnn(X_train_balanced)\n",
        "X_test_cnn = prepare_data_for_cnn(X_test_scaled)\n",
        "y_train_tensor = torch.FloatTensor(y_train_balanced)\n",
        "y_test_tensor = torch.FloatTensor(y_test)\n",
        "\n",
        "# 将数据移动到GPU\n",
        "X_train_cnn = X_train_cnn.to(device)\n",
        "X_test_cnn = X_test_cnn.to(device)\n",
        "y_train_tensor = y_train_tensor.to(device)\n",
        "y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "print(f\"CNN输入数据形状: {X_train_cnn.shape}\")\n",
        "\n",
        "# 创建数据加载器\n",
        "print(\"创建数据加载器...\")\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_cnn, y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 创建验证集数据加载器\n",
        "val_dataset = torch.utils.data.TensorDataset(X_test_cnn, y_test_tensor)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 创建模型\n",
        "print(\"初始化CNN模型...\")\n",
        "model = CNNModel(X_train_balanced.shape[1])\n",
        "model = model.to(device)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# 训练模型\n",
        "print(\"开始训练...\")\n",
        "start_time = time.time()\n",
        "best_val_loss = float('inf')\n",
        "patience = 10\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(50):\n",
        "    # 训练阶段\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch+1}/50\")\n",
        "    for batch_idx, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X).squeeze()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "        \n",
        "        # 计算训练准确率\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct_train += (predicted == batch_y).sum().item()\n",
        "        total_train += batch_y.size(0)\n",
        "        \n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Batch {batch_idx}/{len(train_loader)}, \"\n",
        "                  f\"Loss: {loss.item():.4f}, \"\n",
        "                  f\"Progress: {batch_idx/len(train_loader)*100:.1f}%\")\n",
        "    \n",
        "    # 验证阶段\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            outputs = model(batch_X).squeeze()\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            total_val_loss += loss.item()\n",
        "            \n",
        "            # 计算验证准确率\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct_val += (predicted == batch_y).sum().item()\n",
        "            total_val += batch_y.size(0)\n",
        "    \n",
        "    # 计算平均损失和准确率\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    train_accuracy = correct_train / total_train\n",
        "    val_accuracy = correct_val / total_val\n",
        "    \n",
        "    print(f\"Epoch {epoch+1} 结果:\")\n",
        "    print(f\"训练损失: {avg_train_loss:.4f}, 训练准确率: {train_accuracy:.4f}\")\n",
        "    print(f\"验证损失: {avg_val_loss:.4f}, 验证准确率: {val_accuracy:.4f}\")\n",
        "    \n",
        "    # 学习率调整\n",
        "    scheduler.step(avg_val_loss)\n",
        "    \n",
        "    # 早停检查\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        # 保存最佳模型\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "\n",
        "# 预测\n",
        "print(\"\\n开始预测...\")\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_cnn).squeeze().cpu().numpy()\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "predict_time = time.time() - start_time\n",
        "\n",
        "# 评估CNN模型\n",
        "cnn_result = evaluate_model(y_test, y_pred_binary, 'CNN', 'Deep Learning', \n",
        "                          train_time, predict_time)\n",
        "\n",
        "# 比较CNN与最佳传统模型\n",
        "print(\"\\nCNN vs 最佳传统模型比较\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"CNN - F1分数: {cnn_result['f1']:.4f}, 训练时间: {cnn_result['train_time']:.2f}s\")\n",
        "print(f\"最佳传统模型 ({best_model['model_name']}) - F1分数: {best_model['f1']:.4f}, \"\n",
        "      f\"训练时间: {best_model['train_time']:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
